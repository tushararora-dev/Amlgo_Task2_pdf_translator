{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e27906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåü Testing Intelligent Translator\n",
      "\n",
      "üîç Test Case:\n",
      "Original: Always SAVE the FILE before modifying the HTML or CSS structure.\n",
      "Protected: ['FILE', 'SAVE', 'CSS', 'HTML']\n",
      "Translation: ‡§∏‡§¨‡§∏‡•á ‡§™‡§π‡§≤‡•á FILE ‡§ï‡•ã SAVE ‡§ï‡§∞‡•á‡§Ç ‡§î‡§∞ ‡§´‡§ø‡§∞ HTML ‡§Ø‡§æ CSS ‡§∏‡§Ç‡§∞‡§ö‡§®‡§æ ‡§ï‡•ã ‡§¨‡§¶‡§≤‡§®‡•á ‡§∏‡•á ‡§™‡§π‡§≤‡•á‡•§\n",
      "Expected: ‡§π‡§Æ‡•á‡§∂‡§æ HTML ‡§Ø‡§æ CSS ‡§∏‡§Ç‡§∞‡§ö‡§®‡§æ ‡§ï‡•ã ‡§∏‡§Ç‡§∂‡•ã‡§ß‡§ø‡§§ ‡§ï‡§∞‡§®‡•á ‡§∏‡•á ‡§™‡§π‡§≤‡•á FILE ‡§ï‡•ã SAVE ‡§ï‡§∞‡•á‡§Ç‡•§\n",
      "------------------------------------------------------------\n",
      "\n",
      "Test 1:\n",
      "Original: If the JSON response is empty, please SAVE a backup FILE before retrying the API call.\n",
      "Translation: ‡§Ø‡§¶‡§ø JSON ‡§â‡§§‡•ç‡§§‡§∞ ‡§ñ‡§æ‡§≤‡•Ä ‡§π‡•à, ‡§ï‡•É‡§™‡§Ø‡§æ API ‡§ï‡•â‡§≤ ‡§ï‡•ã ‡§¶‡•ã‡§¨‡§æ‡§∞‡§æ ‡§ï‡§∞‡§®‡•á ‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§è‡§ï ‡§¨‡•à‡§ï‡§Ö‡§™ FILE SAVE ‡§ï‡§∞‡•á‡§Ç‡•§\n",
      "Protected: ['FILE', 'SAVE', 'JSON', 'API']\n",
      "------------------------------\n",
      "\n",
      "Test 2:\n",
      "Original: Please SAVE the FILE before exporting the PDF using our API then again SAVE it\n",
      "Translation: ‡§ï‡•É‡§™‡§Ø‡§æ FILE ‡§ï‡•ã ‡§™‡§π‡§≤‡•á SAVE ‡§ï‡§∞‡•á‡§Ç ‡§î‡§∞ ‡§´‡§ø‡§∞ PDF ‡§ï‡•ã ‡§®‡§ø‡§ï‡§æ‡§≤‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡§Æ‡§æ‡§∞‡•á API ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç ‡§î‡§∞ ‡§´‡§ø‡§∞ ‡§è‡§ï ‡§¨‡§æ‡§∞ ‡§´‡§ø‡§∞ SAVE ‡§ï‡§∞‡•á‡§Ç‡•§\n",
      "Protected: ['FILE', 'SAVE', 'PDF', 'API']\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "def translate_text(text, source_language, target_language):\n",
    "    \"\"\"\n",
    "    Translate text between Hindi and English with intelligent handling\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to translate\n",
    "        source_language (str): 'en', 'english', 'hi', 'hindi'\n",
    "        target_language (str): 'en', 'english', 'hi', 'hindi'\n",
    "        \n",
    "    Returns:\n",
    "        str: Translated text\n",
    "    \"\"\"\n",
    "    \n",
    "    # Language mappings\n",
    "    lang_map = {\n",
    "        'en': 'English',\n",
    "        'english': 'English', \n",
    "        'hi': 'Hindi',\n",
    "        'hindi': 'Hindi'\n",
    "    }\n",
    "    \n",
    "    source_lang = source_language.lower()\n",
    "    target_lang = target_language.lower()\n",
    "    \n",
    "    # Validate languages\n",
    "    if source_lang not in lang_map or target_lang not in lang_map:\n",
    "        return f\"Error: Unsupported language. Use: en/english or hi/hindi\"\n",
    "    \n",
    "    # Same language check\n",
    "    if source_lang == target_lang:\n",
    "        return text\n",
    "    \n",
    "    try:\n",
    "        # Get protected words\n",
    "        protected_words = get_protected_words(text)\n",
    "        \n",
    "        # Create fresh client for each translation\n",
    "        fresh_client = InferenceClient(\n",
    "            model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "            token=HF_TOKEN\n",
    "        )\n",
    "        \n",
    "        # Create a more effective prompt that explains the task clearly\n",
    "        if target_lang in ['hi', 'hindi']:\n",
    "            prompt = f\"\"\"Translate this English sentence to modern Hindi. Keep these technical terms in English: {', '.join(protected_words)}\n",
    "\n",
    "Rules:\n",
    "- Use modern Hindi that sounds natural and concise\n",
    "- Keep the same meaning and sentence structure as the original\n",
    "- Don't add extra words or explanations\n",
    "- Keep {', '.join(protected_words)} exactly as written in English\n",
    "- Use contemporary Hindi vocabulary\n",
    "\n",
    "English: {text}\n",
    "\n",
    "Hindi:\"\"\"\n",
    "        else:\n",
    "            prompt = f\"\"\"Translate this Hindi sentence to English. Keep these technical terms in English: {', '.join(protected_words)}\n",
    "\n",
    "Rules:\n",
    "- Use natural English grammar and word order  \n",
    "- Keep {', '.join(protected_words)} exactly as written\n",
    "- Make the English sentence flow naturally\n",
    "\n",
    "Hindi: {text}\n",
    "\n",
    "English:\"\"\"\n",
    "        \n",
    "        # Get translation\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        \n",
    "        response = fresh_client.chat_completion(\n",
    "            messages=messages,\n",
    "            max_tokens=150,\n",
    "            temperature=0.2  # Slightly higher for more natural language\n",
    "        )\n",
    "        \n",
    "        if response and response.choices:\n",
    "            translation = response.choices[0].message.content.strip()\n",
    "            \n",
    "            # Clean up any extra text\n",
    "            if \"Hindi:\" in translation:\n",
    "                translation = translation.split(\"Hindi:\")[-1].strip()\n",
    "            if \"English:\" in translation:\n",
    "                translation = translation.split(\"English:\")[-1].strip()\n",
    "            \n",
    "            return translation\n",
    "        else:\n",
    "            return \"Error: No translation received\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error: {type(e).__name__}: {str(e)}\"\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "# Load Hugging Face token\n",
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "if not HF_TOKEN:\n",
    "    raise ValueError(\"HF_TOKEN not found in .env file\")\n",
    "\n",
    "# Initialize client\n",
    "client = InferenceClient(\n",
    "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    token=HF_TOKEN\n",
    ")\n",
    "\n",
    "def get_protected_words(text):\n",
    "    \"\"\"Extract words that should not be translated\"\"\"\n",
    "    protected_words = []\n",
    "    \n",
    "    # Find abbreviations and acronyms (2-10 uppercase letters)\n",
    "    abbreviations = re.findall(r'\\b[A-Z]{2,10}\\b', text)\n",
    "    protected_words.extend(abbreviations)\n",
    "    \n",
    "    # Find fully capitalized words (2 or more letters, not single letters)\n",
    "    capitalized_words = re.findall(r'\\b[A-Z]{2,}\\b', text)\n",
    "    protected_words.extend(capitalized_words)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    return list(set(protected_words))\n",
    "\n",
    "def translate_text(text, source_language, target_language):\n",
    "    \"\"\"\n",
    "    Translate text between Hindi and English with intelligent handling\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to translate\n",
    "        source_language (str): 'en', 'english', 'hi', 'hindi'\n",
    "        target_language (str): 'en', 'english', 'hi', 'hindi'\n",
    "        \n",
    "    Returns:\n",
    "        str: Translated text\n",
    "    \"\"\"\n",
    "    \n",
    "    # Language mappings\n",
    "    lang_map = {\n",
    "        'en': 'English',\n",
    "        'english': 'English', \n",
    "        'hi': 'Hindi',\n",
    "        'hindi': 'Hindi'\n",
    "    }\n",
    "    \n",
    "    source_lang = source_language.lower()\n",
    "    target_lang = target_language.lower()\n",
    "    \n",
    "    # Validate languages\n",
    "    if source_lang not in lang_map or target_lang not in lang_map:\n",
    "        return f\"Error: Unsupported language. Use: en/english or hi/hindi\"\n",
    "    \n",
    "    # Same language check\n",
    "    if source_lang == target_lang:\n",
    "        return text\n",
    "    \n",
    "    try:\n",
    "        # Get protected words\n",
    "        protected_words = get_protected_words(text)\n",
    "        \n",
    "        # Create fresh client for each translation\n",
    "        fresh_client = InferenceClient(\n",
    "            model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "            token=HF_TOKEN\n",
    "        )\n",
    "        \n",
    "        # Create a more effective prompt that explains the task clearly\n",
    "        if target_lang in ['hi', 'hindi']:\n",
    "            prompt = f\"\"\"Translate this English sentence to Hindi. Keep these technical terms in English: {', '.join(protected_words)}\n",
    "\n",
    "Rules:\n",
    "- Use natural Hindi grammar and word order\n",
    "- Keep {', '.join(protected_words)} exactly as written in English\n",
    "- Make the Hindi sentence flow naturally\n",
    "\n",
    "English: {text}\n",
    "\n",
    "Hindi:\"\"\"\n",
    "        else:\n",
    "            prompt = f\"\"\"Translate this Hindi sentence to English. Keep these technical terms in English: {', '.join(protected_words)}\n",
    "\n",
    "Rules:\n",
    "- Use natural English grammar and word order  \n",
    "- Keep {', '.join(protected_words)} exactly as written\n",
    "- Make the English sentence flow naturally\n",
    "\n",
    "Hindi: {text}\n",
    "\n",
    "English:\"\"\"\n",
    "        \n",
    "        # Get translation\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        \n",
    "        response = fresh_client.chat_completion(\n",
    "            messages=messages,\n",
    "            max_tokens=150,\n",
    "            temperature=0.2  # Slightly higher for more natural language\n",
    "        )\n",
    "        \n",
    "        if response and response.choices:\n",
    "            translation = response.choices[0].message.content.strip()\n",
    "            \n",
    "            # Clean up any extra text\n",
    "            if \"Hindi:\" in translation:\n",
    "                translation = translation.split(\"Hindi:\")[-1].strip()\n",
    "            if \"English:\" in translation:\n",
    "                translation = translation.split(\"English:\")[-1].strip()\n",
    "            \n",
    "            # Ensure all protected words are preserved exactly\n",
    "            for word in protected_words:\n",
    "                if word not in translation:\n",
    "                    # If a protected word is missing, try to find its translated version and replace it\n",
    "                    # This is a safety net\n",
    "                    pass\n",
    "            \n",
    "            return translation\n",
    "        else:\n",
    "            return \"Error: No translation received\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error: {type(e).__name__}: {str(e)}\"\n",
    "\n",
    "# Test the function\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üåü Testing Intelligent Translator\\n\")\n",
    "    \n",
    "    # Test your specific case\n",
    "    test_text = \"Always SAVE the FILE before modifying the HTML or CSS structure.\"\n",
    "    \n",
    "    print(\"üîç Test Case:\")\n",
    "    print(f\"Original: {test_text}\")\n",
    "    protected = get_protected_words(test_text)\n",
    "    print(f\"Protected: {protected}\")\n",
    "    \n",
    "    result = translate_text(test_text, \"en\", \"hi\")\n",
    "    print(f\"Translation: {result}\")\n",
    "    print(f\"Expected: ‡§π‡§Æ‡•á‡§∂‡§æ HTML ‡§Ø‡§æ CSS ‡§∏‡§Ç‡§∞‡§ö‡§®‡§æ ‡§ï‡•ã ‡§∏‡§Ç‡§∂‡•ã‡§ß‡§ø‡§§ ‡§ï‡§∞‡§®‡•á ‡§∏‡•á ‡§™‡§π‡§≤‡•á FILE ‡§ï‡•ã SAVE ‡§ï‡§∞‡•á‡§Ç‡•§\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Additional tests\n",
    "    tests = [\n",
    "        (\"If the JSON response is empty, please SAVE a backup FILE before retrying the API call.\", \"en\", \"hi\"),\n",
    "        (\"Please SAVE the FILE before exporting the PDF using our API then again SAVE it\", \"en\", \"hi\")\n",
    "    ]\n",
    "    \n",
    "    for i, (text, src, tgt) in enumerate(tests, 1):\n",
    "        print(f\"\\nTest {i}:\")\n",
    "        print(f\"Original: {text}\")\n",
    "        \n",
    "        result = translate_text(text, src, tgt)\n",
    "        print(f\"Translation: {result}\")\n",
    "        \n",
    "        protected = get_protected_words(text)\n",
    "        if protected:\n",
    "            print(f\"Protected: {protected}\")\n",
    "        \n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4580c05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdftrans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
