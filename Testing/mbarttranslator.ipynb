{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d1c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "from typing import List, Optional, Tuple\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/facebook/mbart-large-50-many-to-many-mmt\"\n",
    "HEADERS = {\"Authorization\": f\"Bearer {HF_TOKEN}\"}\n",
    "\n",
    "# Language codes for mBART50\n",
    "MBART_LANG_CODES = {\n",
    "    'en': 'en_XX',\n",
    "    'hi': 'hi_IN'\n",
    "}\n",
    "\n",
    "# Abbreviations to preserve (case-sensitive)\n",
    "ABBREVIATIONS = {\n",
    "    'AI', 'ML', 'API', 'URL', 'PDF', 'HTML', 'CSS', 'JS', 'SQL', 'JSON',\n",
    "    'HTTP', 'HTTPS', 'NASA', 'CPU', 'GPU', 'RAM', 'OCR', 'SAVE', 'FILE' \n",
    "}\n",
    "\n",
    "\n",
    "def translate_text_via_api(text: str, source: str, target: str) -> str:\n",
    "    src_lang = MBART_LANG_CODES.get(source)\n",
    "    tgt_lang = MBART_LANG_CODES.get(target)\n",
    "\n",
    "    if not src_lang or not tgt_lang:\n",
    "        print(f\"❌ Unsupported language pair: {source} → {target}\")\n",
    "        return text\n",
    "\n",
    "    payload = {\n",
    "        \"inputs\": text,\n",
    "        \"parameters\": {\n",
    "            \"src_lang\": src_lang,\n",
    "            \"tgt_lang\": tgt_lang\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(API_URL, headers=HEADERS, json=payload)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()[0]['translation_text']\n",
    "        else:\n",
    "            print(\"Translation API error:\", response.status_code, response.text)\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(\"Translation error:\", e)\n",
    "        return text\n",
    "\n",
    "\n",
    "def mask_special_tokens(text: str) -> Tuple[str, dict]:\n",
    "    replacements = {}\n",
    "\n",
    "    # Step 1: Mask known abbreviations\n",
    "    for abbr in ABBREVIATIONS:\n",
    "        pattern = r'\\b' + re.escape(abbr) + r'\\b'\n",
    "        token = f\"__{abbr}__\"\n",
    "        if re.search(pattern, text):\n",
    "            text = re.sub(pattern, token, text)\n",
    "            replacements[token] = abbr\n",
    "\n",
    "    # Step 2: Mask any other ALLCAPS words of exactly 3 letters\n",
    "    capital_words = re.findall(r'\\b[A-Z]{3}\\b', text)\n",
    "    for word in capital_words:\n",
    "        if word not in ABBREVIATIONS:\n",
    "            token = f\"__{word}__\"\n",
    "            text = text.replace(word, token)\n",
    "            replacements[token] = word\n",
    "\n",
    "    return text, replacements\n",
    "\n",
    "\n",
    "def unmask_special_tokens(text: str, replacements: dict) -> str:\n",
    "    for token, original in replacements.items():\n",
    "        text = text.replace(token, original)\n",
    "    return text\n",
    "\n",
    "\n",
    "def translate_text(text: str, source: str, target: str) -> str:\n",
    "    if not text or not text.strip() or source == target:\n",
    "        return text\n",
    "\n",
    "    # Step 1: Mask special tokens\n",
    "    masked_text, replacements = mask_special_tokens(text)\n",
    "\n",
    "    # Step 2: Translate\n",
    "    translated = translate_text_via_api(masked_text.strip(), source, target)\n",
    "\n",
    "    # Step 3: Unmask\n",
    "    translated = unmask_special_tokens(translated, replacements)\n",
    "\n",
    "    return translated\n",
    "\n",
    "\n",
    "def translate_text_blocks(text_blocks: List[str], source: str, target: str, callback=None) -> List[str]:\n",
    "    if not text_blocks:\n",
    "        return []\n",
    "\n",
    "    translated = []\n",
    "    total = len(text_blocks)\n",
    "\n",
    "    for i, block in enumerate(text_blocks):\n",
    "        if callback:\n",
    "            callback((i + 1) / total, f\"Translating block {i + 1} of {total}\")\n",
    "\n",
    "        translated_block = translate_text(block, source, target)\n",
    "        translated.append(translated_block)\n",
    "\n",
    "        if i < total - 1:\n",
    "            time.sleep(0.1)\n",
    "\n",
    "    return translated\n",
    "\n",
    "\n",
    "def detect_language(text: str) -> Optional[str]:\n",
    "    sample = text[:500].strip()\n",
    "    if not sample:\n",
    "        return None\n",
    "\n",
    "    hindi_chars = sum(1 for char in sample if '\\u0900' <= char <= '\\u097F')\n",
    "    latin_chars = sum(1 for char in sample if char.isalpha() and char.isascii())\n",
    "\n",
    "    if hindi_chars > latin_chars:\n",
    "        return 'hi'\n",
    "    elif latin_chars > 0:\n",
    "        return 'en'\n",
    "    return None\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
